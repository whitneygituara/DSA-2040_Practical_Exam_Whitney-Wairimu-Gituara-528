{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d659d97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of dataset:\n",
      "  InvoiceNo StockCode                          Description  Quantity  \\\n",
      "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
      "1    536365     71053                  WHITE METAL LANTERN         6   \n",
      "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
      "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
      "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
      "\n",
      "      InvoiceDate  UnitPrice  CustomerID         Country  \n",
      "0  12/1/2010 8:26       2.55     17850.0  United Kingdom  \n",
      "1  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n",
      "2  12/1/2010 8:26       2.75     17850.0  United Kingdom  \n",
      "3  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n",
      "4  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n",
      "\n",
      "Missing values count:\n",
      "InvoiceNo           0\n",
      "StockCode           0\n",
      "Description      1454\n",
      "Quantity            0\n",
      "InvoiceDate         0\n",
      "UnitPrice           0\n",
      "CustomerID     135080\n",
      "Country             0\n",
      "dtype: int64\n",
      "\n",
      "Missing values after cleaning:\n",
      "InvoiceNo      0\n",
      "StockCode      0\n",
      "Description    0\n",
      "Quantity       0\n",
      "InvoiceDate    0\n",
      "UnitPrice      0\n",
      "CustomerID     0\n",
      "Country        0\n",
      "dtype: int64\n",
      "\n",
      "Rows remaining after extraction and cleaning: 541909\n",
      "Recent sales preview:\n",
      "Empty DataFrame\n",
      "Columns: [InvoiceNo, StockCode, Description, Quantity, InvoiceDate, UnitPrice, CustomerID, Country, TotalSales, Month, Quarter, Year]\n",
      "Index: []\n",
      "\n",
      "Customer summary preview:\n",
      "  CustomerID  TotalSales  TotalPurchases         Country\n",
      "0    12346.0    77183.60               1  United Kingdom\n",
      "1    12347.0     4310.00             182         Iceland\n",
      "2    12348.0     1797.24              31         Finland\n",
      "3    12349.0     1757.55              73           Italy\n",
      "4    12350.0      334.40              17          Norway\n",
      "Data loaded into retail_dw.db successfully!\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "\n",
    "# Load CSV\n",
    "csv_path = r\"C:\\Users\\Admin\\OneDrive\\Documents\\USIU\\Datawarehousing\\EndSemExam\\DSA-2040_Practical_Exam_Whitney-Wairimu-Gituara-528\\Data_Warehousing\\ETL\\Online Retail.csv\"  \n",
    "data = pd.read_csv(csv_path, encoding='latin1')  \n",
    "\n",
    "# Preview of first few rows\n",
    "print(\"Preview of dataset:\")\n",
    "print(data.head())  \n",
    "\n",
    "# Convertion of InvoiceDate to datetime\n",
    "data['InvoiceDate'] = pd.to_datetime(data['InvoiceDate'], errors='coerce')  \n",
    "# errors='coerce' replaces bad dates with NaT\n",
    "\n",
    "# Count missing values before cleaning\n",
    "print(\"\\nMissing values count:\")\n",
    "print(data.isna().sum())  \n",
    "\n",
    "# Drop rows where essential columns are missing\n",
    "data = data.dropna(subset=['InvoiceNo', 'StockCode', 'Quantity', 'UnitPrice', 'InvoiceDate'])  \n",
    "\n",
    "# Fill missing CustomerID with 'Unknown'\n",
    "data['CustomerID'] = data['CustomerID'].fillna('Unknown')\n",
    "# Fill missing Description with 'No Description'\n",
    "data['Description'] = data['Description'].fillna('No Description')\n",
    "\n",
    "# Summary after cleaning\n",
    "print(\"\\nMissing values after cleaning:\")\n",
    "print(data.isna().sum())  \n",
    "print(\"\\nRows remaining after extraction and cleaning:\", len(data))\n",
    "\n",
    "# Transformation Steps\n",
    "# This includes removing outliers and creating new calculated fields\n",
    "# Remove outliers: drop rows where Quantity is negative or UnitPrice is zero or negative\n",
    "data = data[(data['Quantity'] >= 0) & (data['UnitPrice'] > 0)]\n",
    "\n",
    "# Calculate TotalSales\n",
    "data['TotalSales'] = data['Quantity'] * data['UnitPrice']\n",
    "\n",
    "# Extract Month, Quarter, and Year for time analysis\n",
    "data['Month'] = data['InvoiceDate'].dt.month\n",
    "data['Quarter'] = data['InvoiceDate'].dt.quarter\n",
    "data['Year'] = data['InvoiceDate'].dt.year\n",
    "\n",
    "# Create a customer summary table\n",
    "customer_summary = data.groupby('CustomerID').agg({\n",
    "    'TotalSales': 'sum',\n",
    "    'InvoiceNo': 'count',\n",
    "    'Country': 'first'\n",
    "}).rename(columns={\n",
    "    'InvoiceNo': 'TotalPurchases'\n",
    "}).reset_index()\n",
    "\n",
    "# Filter for sales in the last year (from Aug 12, 2025)\n",
    "end_date = pd.to_datetime('2025-08-12')\n",
    "start_date = end_date - pd.DateOffset(years=1)\n",
    "recent_sales = data[(data['InvoiceDate'] >= start_date) & (data['InvoiceDate'] <= end_date)]\n",
    "\n",
    "# Sort recent sales by InvoiceDate\n",
    "recent_sales = recent_sales.sort_values('InvoiceDate')\n",
    "\n",
    "# Preview the transformed datasets\n",
    "print(\"Recent sales preview:\")\n",
    "print(recent_sales.head())\n",
    "\n",
    "print(\"\\nCustomer summary preview:\")\n",
    "print(customer_summary.head())\n",
    "\n",
    "# Load section\n",
    "# This section includes saving the transformed data to new CSV files\n",
    "import sqlite3 #importing sqlite3 module\n",
    "\n",
    "# Create/connect to a SQLite database file\n",
    "conn = sqlite3.connect(\"retail_dw.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# -------------------------\n",
    "# Creating Dimension Tables\n",
    "# -------------------------\n",
    "\n",
    "# Customer Dimension\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS CustomerDim (\n",
    "    CustomerID TEXT PRIMARY KEY,\n",
    "    Country TEXT\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "# Product Dimension\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS ProductDim (\n",
    "    StockCode TEXT PRIMARY KEY,\n",
    "    Description TEXT\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "# Time Dimension\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS TimeDim (\n",
    "    TimeID INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    InvoiceDate DATE,\n",
    "    Year INTEGER,\n",
    "    Quarter INTEGER,\n",
    "    Month INTEGER\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "# Country Dimension\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS CountryDim (\n",
    "    Country TEXT PRIMARY KEY\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "# -------------------------\n",
    "# Fact Table creation\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS SalesFact (\n",
    "    InvoiceNo TEXT,\n",
    "    CustomerID TEXT,\n",
    "    StockCode TEXT,\n",
    "    InvoiceDate DATE,\n",
    "    Quantity INTEGER,\n",
    "    UnitPrice REAL,\n",
    "    TotalSales REAL,\n",
    "    FOREIGN KEY (CustomerID) REFERENCES CustomerDim(CustomerID),\n",
    "    FOREIGN KEY (StockCode) REFERENCES ProductDim(StockCode),\n",
    "    FOREIGN KEY (InvoiceDate) REFERENCES TimeDim(InvoiceDate)\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Inserting data into Dimension Tables\n",
    "\n",
    "# Customer Dimension\n",
    "customer_data = data[['CustomerID', 'Country']].drop_duplicates()\n",
    "customer_data.to_sql('CustomerDim', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Product Dimension\n",
    "product_data = data[['StockCode', 'Description']].drop_duplicates()\n",
    "product_data.to_sql('ProductDim', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Time Dimension\n",
    "time_data = data[['InvoiceDate', 'Year', 'Quarter', 'Month']].drop_duplicates()\n",
    "time_data.to_sql('TimeDim', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Country Dimension\n",
    "country_data = data[['Country']].drop_duplicates()\n",
    "country_data.to_sql('CountryDim', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Inserting data into the Fact Table\n",
    "fact_data = data[['InvoiceNo', 'CustomerID', 'StockCode', 'InvoiceDate', 'Quantity', 'UnitPrice', 'TotalSales']]\n",
    "fact_data.to_sql('SalesFact', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Commit and close connection\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(\"Data loaded into retail_dw.db successfully!\")\n",
    "\n",
    "# Function that performs the full ETL process and logs the number of rows processed at each stage.\n",
    "def full_etl_process(csv_path, db_name=\"retail_dw.db\"):\n",
    "    \"\"\" \n",
    "    Performs the full ETL process: Extract, Transform, Load.\n",
    "    Logs the number of rows at each stage.\n",
    "    \n",
    "    Parameters:\n",
    "        csv_path (str): Path to the CSV file\n",
    "        db_name (str): Name of the SQLite database file to create\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # -------------------------\n",
    "        # Extract\n",
    "        # -------------------------\n",
    "        print(\"=== Extract Stage ===\")\n",
    "        # Read CSV into a pandas DataFrame\n",
    "        # This is the first step to bring raw data into Python for processing\n",
    "        data = pd.read_csv(csv_path, encoding='latin1')\n",
    "        print(\"Rows read from CSV:\", len(data))\n",
    "        \n",
    "        # Convert InvoiceDate to datetime\n",
    "        # This allows us to easily filter, sort, and extract time attributes\n",
    "        data['InvoiceDate'] = pd.to_datetime(data['InvoiceDate'], errors='coerce')\n",
    "        \n",
    "        # Drop rows missing essential values to avoid errors in calculations or database load\n",
    "        data = data.dropna(subset=['InvoiceNo', 'StockCode', 'Quantity', 'UnitPrice', 'InvoiceDate'])\n",
    "        print(\"Rows after dropping essential missing values:\", len(data))\n",
    "        \n",
    "        # Fill missing CustomerID with 'Unknown' to avoid null values in dimension table\n",
    "        # This ensures every transaction is linked to a customer\n",
    "        data['CustomerID'] = data['CustomerID'].fillna('Unknown')\n",
    "        print(\"Rows after filling missing CustomerID:\", len(data))\n",
    "        \n",
    "        # -------------------------\n",
    "        # Transform\n",
    "        # -------------------------\n",
    "        print(\"\\n=== Transform Stage ===\")\n",
    "        \n",
    "        # Remove outliers: negative Quantity or non-positive UnitPrice\n",
    "        # Outliers could distort totals and summaries, so we filter them out\n",
    "        data = data[(data['Quantity'] >= 0) & (data['UnitPrice'] > 0)]\n",
    "        print(\"Rows after removing outliers:\", len(data))\n",
    "        \n",
    "        # Calculate TotalSales for each transaction\n",
    "        # This will be used in the fact table for sales analysis\n",
    "        data['TotalSales'] = data['Quantity'] * data['UnitPrice']\n",
    "        \n",
    "        # Extract Month, Quarter, and Year for time dimension\n",
    "        # These are used to analyze sales over different periods\n",
    "        data['Month'] = data['InvoiceDate'].dt.month\n",
    "        data['Quarter'] = data['InvoiceDate'].dt.quarter\n",
    "        data['Year'] = data['InvoiceDate'].dt.year\n",
    "        \n",
    "        # Create customer summary table for CustomerDim\n",
    "        # Aggregates total sales, total purchases, and keeps country info\n",
    "        customer_summary = data.groupby('CustomerID').agg({\n",
    "            'TotalSales': 'sum',\n",
    "            'InvoiceNo': 'count',\n",
    "            'Country': 'first'\n",
    "        }).rename(columns={'InvoiceNo': 'TotalPurchases'}).reset_index()\n",
    "        print(\"Customer summary rows:\", len(customer_summary))\n",
    "        \n",
    "        # Filter recent sales (Aug 12, 2024 → Aug 12, 2025)\n",
    "        # This creates a subset for analyzing last year’s performance\n",
    "        end_date = pd.to_datetime('2025-08-12')\n",
    "        start_date = end_date - pd.DateOffset(years=1)\n",
    "        recent_sales = data[(data['InvoiceDate'] >= start_date) & (data['InvoiceDate'] <= end_date)]\n",
    "        print(\"Recent sales rows (last year):\", len(recent_sales))\n",
    "        \n",
    "        # -------------------------\n",
    "        # Load\n",
    "        # -------------------------\n",
    "        print(\"\\n=== Load Stage ===\")\n",
    "        try:\n",
    "            # Connect to SQLite database\n",
    "            # Using a database allows us to store structured data for reporting and analysis\n",
    "            conn = sqlite3.connect(db_name)\n",
    "            \n",
    "            # Load dimension tables first\n",
    "            # Dimensions contain descriptive data used to categorize and filter facts\n",
    "            customer_summary.to_sql('CustomerDim', conn, if_exists='replace', index=False)\n",
    "            \n",
    "            # Product dimension: unique products with description\n",
    "            product_data = data[['StockCode', 'Description']].drop_duplicates()\n",
    "            product_data.to_sql('ProductDim', conn, if_exists='replace', index=False)\n",
    "            \n",
    "            # Time dimension: unique invoice dates with extracted Year, Quarter, Month\n",
    "            time_data = data[['InvoiceDate', 'Year', 'Quarter', 'Month']].drop_duplicates()\n",
    "            time_data.to_sql('TimeDim', conn, if_exists='replace', index=False)\n",
    "            \n",
    "            # Country dimension: unique countries\n",
    "            country_data = data[['Country']].drop_duplicates()\n",
    "            country_data.to_sql('CountryDim', conn, if_exists='replace', index=False)\n",
    "            \n",
    "            # Load fact table after dimensions\n",
    "            # Facts contain measurable data (sales, quantities) and link to dimensions via keys\n",
    "            fact_data = data[['InvoiceNo', 'CustomerID', 'StockCode', 'InvoiceDate', 'Quantity', 'UnitPrice', 'TotalSales','Country']]\n",
    "            fact_data.to_sql('SalesFact', conn, if_exists='replace', index=False)\n",
    "            \n",
    "            conn.commit()\n",
    "            print(\"Data loaded into database:\", db_name)\n",
    "            print(\"Fact table rows:\", len(fact_data))\n",
    "        except sqlite3.Error as e:\n",
    "            print(\"Database error:\", e)\n",
    "        finally:\n",
    "            conn.close()\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: CSV file not found at path: {csv_path}\")\n",
    "    except pd.errors.ParserError:\n",
    "        print(\"Error: Could not parse CSV file. Check file format.\")\n",
    "    except Exception as e:\n",
    "        print(\"Unexpected error:\", e)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
